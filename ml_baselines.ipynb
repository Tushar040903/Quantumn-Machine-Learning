{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e71ce71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Loading Fashion-MNIST dataset ...\n",
      "\n",
      "üöÄ Training Logistic Regression ...\n",
      "‚úÖ Logistic Regression Accuracy: 80.88% | Time: 23.3s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.757     0.774     0.765      1000\n",
      "           1      0.950     0.956     0.953      1000\n",
      "           2      0.686     0.701     0.693      1000\n",
      "           3      0.818     0.798     0.808      1000\n",
      "           4      0.679     0.715     0.697      1000\n",
      "           5      0.912     0.893     0.902      1000\n",
      "           6      0.570     0.507     0.537      1000\n",
      "           7      0.889     0.915     0.902      1000\n",
      "           8      0.899     0.901     0.900      1000\n",
      "           9      0.910     0.928     0.919      1000\n",
      "\n",
      "    accuracy                          0.809     10000\n",
      "   macro avg      0.807     0.809     0.808     10000\n",
      "weighted avg      0.807     0.809     0.808     10000\n",
      "\n",
      "\n",
      "üöÄ Training SVM (RBF Kernel) ...\n",
      "‚úÖ SVM (RBF Kernel) Accuracy: 87.31% | Time: 64.0s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.813     0.834     0.823      1000\n",
      "           1      0.992     0.960     0.976      1000\n",
      "           2      0.789     0.798     0.794      1000\n",
      "           3      0.857     0.881     0.869      1000\n",
      "           4      0.782     0.805     0.793      1000\n",
      "           5      0.967     0.953     0.960      1000\n",
      "           6      0.698     0.631     0.663      1000\n",
      "           7      0.931     0.950     0.941      1000\n",
      "           8      0.942     0.972     0.957      1000\n",
      "           9      0.951     0.947     0.949      1000\n",
      "\n",
      "    accuracy                          0.873     10000\n",
      "   macro avg      0.872     0.873     0.872     10000\n",
      "weighted avg      0.872     0.873     0.872     10000\n",
      "\n",
      "\n",
      "üöÄ Training Random Forest ...\n",
      "‚úÖ Random Forest Accuracy: 86.18% | Time: 9.1s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.798     0.855     0.826      1000\n",
      "           1      0.991     0.948     0.969      1000\n",
      "           2      0.748     0.784     0.766      1000\n",
      "           3      0.848     0.899     0.873      1000\n",
      "           4      0.741     0.800     0.769      1000\n",
      "           5      0.976     0.945     0.960      1000\n",
      "           6      0.708     0.536     0.610      1000\n",
      "           7      0.919     0.933     0.926      1000\n",
      "           8      0.946     0.971     0.959      1000\n",
      "           9      0.930     0.947     0.939      1000\n",
      "\n",
      "    accuracy                          0.862     10000\n",
      "   macro avg      0.861     0.862     0.860     10000\n",
      "weighted avg      0.861     0.862     0.860     10000\n",
      "\n",
      "\n",
      "üöÄ Training Gradient Boosting ...\n",
      "‚úÖ Gradient Boosting Accuracy: 85.53% | Time: 1779.6s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.803     0.821     0.812      1000\n",
      "           1      0.989     0.955     0.972      1000\n",
      "           2      0.742     0.767     0.755      1000\n",
      "           3      0.851     0.881     0.866      1000\n",
      "           4      0.749     0.773     0.761      1000\n",
      "           5      0.966     0.940     0.953      1000\n",
      "           6      0.657     0.587     0.620      1000\n",
      "           7      0.921     0.933     0.927      1000\n",
      "           8      0.944     0.952     0.948      1000\n",
      "           9      0.922     0.944     0.933      1000\n",
      "\n",
      "    accuracy                          0.855     10000\n",
      "   macro avg      0.854     0.855     0.855     10000\n",
      "weighted avg      0.854     0.855     0.855     10000\n",
      "\n",
      "\n",
      "üöÄ Training KNN (k=5) ...\n",
      "‚úÖ KNN (k=5) Accuracy: 82.81% | Time: 0.7s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.743     0.842     0.789      1000\n",
      "           1      0.992     0.957     0.974      1000\n",
      "           2      0.707     0.769     0.737      1000\n",
      "           3      0.889     0.831     0.859      1000\n",
      "           4      0.726     0.747     0.736      1000\n",
      "           5      0.990     0.785     0.876      1000\n",
      "           6      0.597     0.543     0.569      1000\n",
      "           7      0.835     0.940     0.884      1000\n",
      "           8      0.975     0.909     0.941      1000\n",
      "           9      0.880     0.958     0.917      1000\n",
      "\n",
      "    accuracy                          0.828     10000\n",
      "   macro avg      0.833     0.828     0.828     10000\n",
      "weighted avg      0.833     0.828     0.828     10000\n",
      "\n",
      "\n",
      "üöÄ Training MLP (Sklearn) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tusha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ MLP (Sklearn) Accuracy: 86.51% | Time: 54.1s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.787     0.816     0.801      1000\n",
      "           1      0.977     0.969     0.973      1000\n",
      "           2      0.843     0.749     0.793      1000\n",
      "           3      0.893     0.819     0.854      1000\n",
      "           4      0.775     0.819     0.796      1000\n",
      "           5      0.967     0.936     0.951      1000\n",
      "           6      0.623     0.698     0.658      1000\n",
      "           7      0.907     0.967     0.936      1000\n",
      "           8      0.963     0.938     0.950      1000\n",
      "           9      0.959     0.940     0.949      1000\n",
      "\n",
      "    accuracy                          0.865     10000\n",
      "   macro avg      0.869     0.865     0.866     10000\n",
      "weighted avg      0.869     0.865     0.866     10000\n",
      "\n",
      "\n",
      "üìä Final Accuracy Summary:\n",
      "Logistic Regression: 80.88%\n",
      "SVM (RBF Kernel): 87.31%\n",
      "Random Forest: 86.18%\n",
      "Gradient Boosting: 85.53%\n",
      "KNN (k=5): 82.81%\n",
      "MLP (Sklearn): 86.51%\n",
      "\n",
      "‚úÖ All classical models trained and saved successfully.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Classical Machine Learning Baselines for Fashion-MNIST\n",
    "-----------------------------------------------------\n",
    "This script trains multiple classical ML models on flattened image data.\n",
    "It provides a comparative benchmark for deep and quantum-inspired models.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from tensorflow.keras import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n",
    "\n",
    "# =========================================\n",
    "# 1Ô∏è‚É£ Load Fashion-MNIST Dataset\n",
    "# =========================================\n",
    "print(\"üì• Loading Fashion-MNIST dataset ...\")\n",
    "(x_train, y_train), (x_test, y_test) = datasets.fashion_mnist.load_data()\n",
    "\n",
    "# Flatten 28x28 images ‚Üí 784 features\n",
    "x_train = x_train.reshape(len(x_train), -1) / 255.0\n",
    "x_test = x_test.reshape(len(x_test), -1) / 255.0\n",
    "\n",
    "# Optional: use subset for faster testing (remove if you want full training)\n",
    "x_train, _, y_train, _ = train_test_split(x_train, y_train, test_size=0.7, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "# =========================================\n",
    "# 2Ô∏è‚É£ Define Models\n",
    "# =========================================\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=300, n_jobs=-1),\n",
    "    \"SVM (RBF Kernel)\": SVC(kernel='rbf', C=3, gamma='scale'),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=150, random_state=42, n_jobs=-1),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=100),\n",
    "    \"KNN (k=5)\": KNeighborsClassifier(n_neighbors=5, n_jobs=-1),\n",
    "    \"MLP (Sklearn)\": MLPClassifier(hidden_layer_sizes=(256,128), activation='relu', max_iter=30)\n",
    "}\n",
    "\n",
    "# =========================================\n",
    "# 3Ô∏è‚É£ Train & Evaluate Models\n",
    "# =========================================\n",
    "os.makedirs(\"models/classical\", exist_ok=True)\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nüöÄ Training {name} ...\")\n",
    "    start = time.time()\n",
    "    model.fit(x_train, y_train)\n",
    "    duration = time.time() - start\n",
    "\n",
    "    y_pred = model.predict(x_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    results[name] = round(acc * 100, 2)\n",
    "\n",
    "    print(f\"‚úÖ {name} Accuracy: {acc*100:.2f}% | Time: {duration:.1f}s\")\n",
    "    print(classification_report(y_test, y_pred, digits=3))\n",
    "\n",
    "    # Save model\n",
    "    joblib.dump(model, f\"models/classical/{name.replace(' ','_').lower()}.pkl\")\n",
    "\n",
    "# =========================================\n",
    "# 4Ô∏è‚É£ Save Results Summary\n",
    "# =========================================\n",
    "import json\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "with open(\"results/classical_model_accuracies.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=4)\n",
    "\n",
    "print(\"\\nüìä Final Accuracy Summary:\")\n",
    "for k, v in results.items():\n",
    "    print(f\"{k}: {v:.2f}%\")\n",
    "\n",
    "print(\"\\n‚úÖ All classical models trained and saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223af926",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
